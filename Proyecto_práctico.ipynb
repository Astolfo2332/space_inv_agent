{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Actividad - Proyecto práctico\n",
    "\n",
    "\n",
    "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
    "*   Alumno 1:\n",
    "*   Alumno 2:\n",
    "*   Alumno 3:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "jUehXgCyIRdq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## **PARTE 1** - Instalación y requisitos previos\n",
    "\n",
    "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
    "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
    "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
    "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
    "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
   ],
   "metadata": {
    "id": "JwpYlnjWJhS9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1.1. Preparar enviroment (solo local)\n",
    "\n",
    "\n",
    "\n",
    "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
    "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
    "2. Instalar Anaconda\n",
    "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
    "\n",
    "\n",
    "```\n",
    "conda create --name miar_rl python=3.8\n",
    "conda activate miar_rl\n",
    "cd \"PATH_TO_FOLDER\"\n",
    "conda install git\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "\n",
    "4. Abrir la notebook con *jupyter-notebook*.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "jupyter-notebook\n",
    "```\n"
   ],
   "metadata": {
    "id": "RU2BPrK2JkP0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1.2. Localizar entorno de trabajo: Google colab o local"
   ],
   "metadata": {
    "id": "w-kixNPiJqTc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from networkx.tests.test_all_random_functions import progress\n",
    "\n",
    "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
    "mount='/content/gdrive'\n",
    "drive_root = mount + \"/My Drive/08_MIAR/actividades/proyecto practico\"\n",
    "\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  IN_COLAB=True\n",
    "except:\n",
    "  IN_COLAB=False"
   ],
   "metadata": {
    "id": "S_YDFwZ-JscI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1.3. Montar carpeta de datos local (solo Colab)"
   ],
   "metadata": {
    "id": "8Dp_a1iBJ0tf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Switch to the directory on the Google Drive that you want to use\n",
    "import os\n",
    "if IN_COLAB:\n",
    "  print(\"We're running Colab\")\n",
    "\n",
    "  if IN_COLAB:\n",
    "    # Mount the Google Drive at mount\n",
    "    print(\"Colab: mounting Google drive on \", mount)\n",
    "\n",
    "    drive.mount(mount)\n",
    "\n",
    "    # Create drive_root if it doesn't exist\n",
    "    create_drive_root = True\n",
    "    if create_drive_root:\n",
    "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
    "      os.makedirs(drive_root, exist_ok=True)\n",
    "\n",
    "    # Change to the directory\n",
    "    print(\"\\nColab: Changing directory to \", drive_root)\n",
    "    %cd $drive_root\n",
    "# Verify we're in the correct working directory\n",
    "%pwd\n",
    "print(\"Archivos en el directorio: \")\n",
    "print(os.listdir())"
   ],
   "metadata": {
    "id": "I6n7MIefJ21i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1.4. Instalar librerías necesarias"
   ],
   "metadata": {
    "id": "i1ZSL5bpJ560"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install tensorflow==2.8\n",
    "else:\n",
    "  %pip install gym==0.17.3\n",
    "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
    "  %pip install pyglet==1.5.0\n",
    "  %pip install h5py==3.1.0\n",
    "  %pip install Pillow==9.5.0\n",
    "  %pip install keras-rl2==1.0.5\n",
    "  %pip install Keras==2.2.4\n",
    "  %pip install tensorflow==2.5.3\n",
    "  %pip install torch==2.0.1\n",
    "  %pip install agents==1.4.0"
   ],
   "metadata": {
    "id": "UbVRjvHCJ8UF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hzP_5ZuGb2X"
   },
   "source": [
    "---\n",
    "## **PARTE 2**. Enunciado\n",
    "\n",
    "Consideraciones a tener en cuenta:\n",
    "\n",
    "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
    "\n",
    "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
    "\n",
    "Este proyecto práctico consta de tres partes:\n",
    "\n",
    "1.   Implementar la red neuronal que se usará en la solución\n",
    "2.   Implementar las distintas piezas de la solución DQN\n",
    "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
    "\n",
    "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
    "\n",
    "IMPORTANTE:\n",
    "\n",
    "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
    "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
    "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
    "* Cada alumno deberá de subir la solución de forma individual."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## **PARTE 3**. Desarrollo y preguntas"
   ],
   "metadata": {
    "id": "6_b3mzw8IzJP"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duPmUNOVGb2a"
   },
   "source": [
    "#### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j3eRhgI-Gb2a",
    "ExecuteTime": {
     "end_time": "2025-06-15T20:52:41.891300Z",
     "start_time": "2025-06-15T20:52:38.589882Z"
    }
   },
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import ProgressBarCallback, BaseCallback\n",
    "\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "\n",
    "\n",
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import mlflow\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4jgQjzoGb2a"
   },
   "source": [
    "\n",
    "#### Configuración base"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:52:42.104900Z",
     "start_time": "2025-06-15T20:52:41.901833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "INPUT_SHAPE = (1, 84, 84)\n",
    "WINDOW_LENGTH = 4\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "class ClipRewardWrapper(gym.RewardWrapper):\n",
    "    def reward(self, reward):\n",
    "        return np.clip(reward, -1.0, 1.0)\n",
    "\n",
    "env_name = 'SpaceInvaders-v0'\n",
    "env = gym.make(env_name)\n",
    "env = ClipRewardWrapper(env)\n",
    "\n",
    "np.random.seed(123)\n",
    "obs, info = env.reset(seed=123)\n",
    "nb_actions = env.action_space.n\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiki/anaconda3/envs/pytorch/lib/python3.12/site-packages/gymnasium/envs/registration.py:519: DeprecationWarning: \u001B[33mWARN: The environment SpaceInvaders-v0 is out of date. You should consider upgrading to version `v4`.\u001B[0m\n",
      "  logger.deprecation(\n",
      "A.L.E: Arcade Learning Environment (version 0.11.1+2750686)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yitXTADGb2b"
   },
   "source": [
    "1. Implementación de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O4GKrfWSGb2b",
    "ExecuteTime": {
     "end_time": "2025-06-15T23:43:40.064476Z",
     "start_time": "2025-06-15T23:43:40.061296Z"
    }
   },
   "source": [
    "class MobileNetFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        # Pretrained MobileNetV2 without the classifier\n",
    "        weights = torchvision.models.MobileNet_V2_Weights.DEFAULT\n",
    "        self.backbone = torchvision.models.mobilenet_v2(weights=weights)\n",
    "\n",
    "        # Freeze weights (optional)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            sample = torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            if sample.shape[1] != 3:  # Convert grayscale to 3 channels\n",
    "                sample = sample.repeat(1, 3, 1, 1)\n",
    "            n_flatten = self.backbone(sample).view(sample.shape[0], -1).shape[1]\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_flatten, features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Convert 1-channel grayscale to 3 channels if needed\n",
    "        if obs.shape[1] == 1:\n",
    "            obs = obs.repeat(1, 3, 1, 1)\n",
    "        features = self.backbone(obs)\n",
    "        return self.projector(features)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convirtiendo las imágenes a 3 canales"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:12:33.897196Z",
     "start_time": "2025-06-15T05:12:33.893487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VitB16FeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        # Load a pretrained ViT model\n",
    "        weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "        self.backbone = torchvision.models.vit_b_16(weights=weights).cuda()\n",
    "\n",
    "        # Freeze weights (optional)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            sample = torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            if sample.shape[1] != 3:  # Convert grayscale to 3 channels\n",
    "                sample = sample.repeat(1, 3, 1, 1)\n",
    "            sample = self._preprocess(sample).cuda()\n",
    "            n_flatten = self.backbone(sample).view(sample.shape[0], -1).shape[1]\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_flatten, features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _preprocess(self, observation):\n",
    "        # Preprocess the observation to match the input requirements of ViT\n",
    "        batch_resize = F.interpolate(\n",
    "            observation, size=(224, 224), mode='bilinear', align_corners=False\n",
    "        )\n",
    "        return batch_resize\n",
    "\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Convert 1-channel grayscale to 3 channels if needed\n",
    "        obs = self._preprocess(obs).cuda()\n",
    "        if obs.shape[1] == 1:\n",
    "            obs = obs.repeat(1, 3, 1, 1)\n",
    "        features = self.backbone(obs)\n",
    "        return self.projector(features)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Escala de grises"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:52:59.353183Z",
     "start_time": "2025-06-15T20:52:59.349540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VitB16FeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        # Load a pretrained ViT model\n",
    "        weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "        self.backbone = torchvision.models.vit_b_16(weights=weights).cuda()\n",
    "\n",
    "        # Freeze weights (optional)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            sample = torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            if sample.shape[1] != 3:  # Convert grayscale to 3 channels\n",
    "                sample = sample.repeat(1, 3, 1, 1)\n",
    "            sample = self._preprocess(sample).cuda()\n",
    "            n_flatten = self.backbone(sample).view(sample.shape[0], -1).shape[1]\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_flatten, features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _preprocess(self, observation):\n",
    "        # Preprocess the observation to match the input requirements of ViT\n",
    "\n",
    "        r, g, b = observation[:, 0:1, :, :], observation[:, 1:2, :, :], observation[:, 2:3, :, :]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        gray3 = gray.repeat(1, 3, 1, 1)  # Convert to 3 channels\n",
    "\n",
    "        batch_resize = F.interpolate(\n",
    "            gray3, size=(224, 224), mode='bilinear', align_corners=False\n",
    "        )\n",
    "        return batch_resize\n",
    "\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Convert 1-channel grayscale to 3 channels if needed\n",
    "        obs = self._preprocess(obs).cuda()\n",
    "        if obs.shape[1] == 1:\n",
    "            obs = obs.repeat(1, 3, 1, 1)\n",
    "        features = self.backbone(obs)\n",
    "        return self.projector(features)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:53:23.152279Z",
     "start_time": "2025-06-15T20:53:23.148792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResNet152FeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        # Load a pretrained ResNet152 model\n",
    "        weights = torchvision.models.ResNet152_Weights.DEFAULT\n",
    "        self.backbone = torchvision.models.resnet152(weights=weights)\n",
    "\n",
    "        # Freeze weights (optional)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            sample = torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            if sample.shape[1] != 3:  # Convert grayscale to 3 channels\n",
    "                sample = sample.repeat(1, 3, 1, 1)\n",
    "            n_flatten = self.backbone(sample).view(sample.shape[0], -1).shape[1]\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_flatten, features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Convert 1-channel grayscale to 3 channels if needed\n",
    "        if obs.shape[1] == 1:\n",
    "            obs = obs.repeat(1, 3, 1, 1)\n",
    "        features = self.backbone(obs)\n",
    "        return self.projector(features)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T00:18:51.272846Z",
     "start_time": "2025-06-16T00:18:51.265964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNNConnectedDeep(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        # Primeras capas\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        # Concatenación de conv1 y conv3\n",
    "        # 32 (resized conv1) + 64 = 96\n",
    "        # Bloques de compresión adicionales con conexiones\n",
    "        self.conv4 = nn.Conv2d(96, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 160, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(160)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(160, 192, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(192)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(192 + 128, 224, kernel_size=3, padding=1)  # concat con out4\n",
    "        self.bn7 = nn.BatchNorm2d(224)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(224 + 160, 256, kernel_size=3, padding=1)  # concat con out5\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((4, 4))  # reduce a [B, 256, 4, 4]\n",
    "\n",
    "        # Flatten: 256 * 4 * 4 = 4096 → muy alto → reducimos\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, features_dim)\n",
    "\n",
    "    def _preprocess(self, observation):\n",
    "        r, g, b = observation[:, 0:1, :, :], observation[:, 1:2, :, :], observation[:, 2:3, :, :]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        gray3 = gray.repeat(1, 3, 1, 1)  # Convert to 3 channels\n",
    "\n",
    "        batch_resize = F.interpolate(\n",
    "            gray3, size=(224, 224), mode='bilinear', align_corners=False\n",
    "        )\n",
    "        return batch_resize\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._preprocess(x)  # Convert grayscale to 3 channels and resize to 224x224\n",
    "        out1 = F.relu(self.bn1(self.conv1(x)))  # [B, 32, 224, 224]\n",
    "        out2 = F.relu(self.bn2(self.conv2(out1)))\n",
    "        out2 = out1 + out2  # Residual connection\n",
    "        out2 = self.pool(out2)  # [B, 32, 112, 112]\n",
    "\n",
    "        out3 = F.relu(self.bn3(self.conv3(out2)))\n",
    "        out3 = self.pool(out3)  # [B, 64, 56, 56]\n",
    "\n",
    "        out1_resized = F.interpolate(out1, size=out3.shape[2:])\n",
    "        concat1 = torch.cat((out3, out1_resized), dim=1)  # [B, 96, 56, 56]\n",
    "\n",
    "        # Bloque 4\n",
    "        out4 = F.relu(self.bn4(self.conv4(concat1)))\n",
    "        out4 = self.pool(out4)  # [B, 128, 28, 28]\n",
    "\n",
    "        # Bloque 5\n",
    "        out5 = F.relu(self.bn5(self.conv5(out4)))\n",
    "        out5 = self.pool(out5)  # [B, 160, 14, 14]\n",
    "\n",
    "        # Bloque 6\n",
    "        out6 = F.relu(self.bn6(self.conv6(out5)))\n",
    "        out6 = self.pool(out6)  # [B, 192, 7, 7]\n",
    "\n",
    "        # Concat out4 (resized) con out6\n",
    "        out4_resized = F.interpolate(out4, size=out6.shape[2:])\n",
    "        concat2 = torch.cat((out6, out4_resized), dim=1)  # [B, 192+128=320, 7, 7]\n",
    "        out7 = F.relu(self.bn7(self.conv7(concat2)))\n",
    "\n",
    "        # Concat out5 (resized) con out7\n",
    "        out5_resized = F.interpolate(out5, size=out7.shape[2:])\n",
    "        concat3 = torch.cat((out7, out5_resized), dim=1)  # [B, 224+160=384, 7, 7]\n",
    "        out8 = F.relu(self.bn8(self.conv8(concat3)))\n",
    "\n",
    "        x = self.global_pool(out8)  # [B, 256, 4, 4]\n",
    "        x = x.view(x.size(0), -1)   # Flatten → [B, 4096]\n",
    "\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # 4096 → 512\n",
    "        out = self.fc2(x)  # 512 → num_classes\n",
    "\n",
    "        return out\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB9-_5HPGb2b"
   },
   "source": [
    "2. Implementación de la solución DQN"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:53:02.853736Z",
     "start_time": "2025-06-15T20:53:02.850751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TQDMProgressCallback(BaseCallback):\n",
    "    def __init__(self, total_timesteps: int, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.progress_bar = None\n",
    "        self.last_timesteps = 0\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        self.progress_bar = tqdm(total=self.total_timesteps, desc=\"Training Progress\", unit=\"step\")\n",
    "\n",
    "    def _on_step(self):\n",
    "        steps_since_last = self.num_timesteps - self.last_timesteps\n",
    "        self.progress_bar.update(steps_since_last)\n",
    "        self.last_timesteps += 1\n",
    "\n",
    "        # Optional: log latest reward if available\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        if infos and isinstance(infos[0], dict) and \"episode\" in infos[0]:\n",
    "            self.progress_bar.set_postfix(reward=infos[0][\"episode\"][\"r\"])\n",
    "        return True  # Return True to continue training\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        self.progress_bar.close()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:53:04.213753Z",
     "start_time": "2025-06-15T20:53:04.209589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class MLflowCallback(BaseCallback):\n",
    "    def __init__(self, best_model_path, experiment_name=\"SB3_Experiment\", run_name=None, log_freq=1000, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.experiment_name = experiment_name\n",
    "        self.log_freq = log_freq\n",
    "        self.step_count = 0\n",
    "        self.best_mean_reward = -np.inf\n",
    "        self.best_model_path = best_model_path\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        self.step_count += 1\n",
    "        if self.step_count % self.log_freq == 0:\n",
    "            rewards = [ep_info['r'] for ep_info in self.model.ep_info_buffer] if self.model.ep_info_buffer else []\n",
    "            lengths = [ep_info['l'] for ep_info in self.model.ep_info_buffer] if self.model.ep_info_buffer else []\n",
    "\n",
    "            mean_reward = np.mean(rewards) if rewards else 0.0\n",
    "            max_reward = np.max(rewards) if rewards else 0.0\n",
    "            min_reward = np.min(rewards) if rewards else 0.0\n",
    "            mean_length = np.mean(lengths) if lengths else 0.0\n",
    "            std_reward = np.std(rewards) if rewards else 0.0\n",
    "\n",
    "            step = self.num_timesteps\n",
    "            mlflow.log_metric(\"timesteps\", step, step=step)\n",
    "            mlflow.log_metric(\"episode_reward_mean\", mean_reward, step=step)\n",
    "            mlflow.log_metric(\"episode_reward_max\", max_reward, step=step)\n",
    "            mlflow.log_metric(\"episode_reward_min\", min_reward, step=step)\n",
    "            mlflow.log_metric(\"episode_length_mean\", mean_length, step=step)\n",
    "            mlflow.log_metric(\"episode_reward_std\", std_reward, step=step)\n",
    "\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                self.best_mean_reward = mean_reward\n",
    "                # Save the best model\n",
    "                self.model.save(self.best_model_path)\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        # Optionally save the model as artifact\n",
    "        mlflow.log_param(\"num_episodes\", len(self.model.ep_info_buffer))\n",
    "        mlflow.end_run()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T20:53:06.914414Z",
     "start_time": "2025-06-15T20:53:06.911171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TestCallBack(BaseCallback):\n",
    "    def __init__(self, env, n_episodes=10, verbose=0, test_timesteps=10000):\n",
    "        super().__init__(verbose)\n",
    "        self.env = env\n",
    "        self.n_episodes = n_episodes\n",
    "        self.rewards = []\n",
    "        self.test_timesteps = test_timesteps\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.num_timesteps % self.test_timesteps == 0:  # Test every 1000 steps\n",
    "            for _ in range(self.n_episodes):\n",
    "                ep_reward = 0\n",
    "                obs, _ = self.env.reset()\n",
    "                done = False\n",
    "                while not done:\n",
    "                    with torch.no_grad():\n",
    "                        action, _ = self.model.predict(obs)\n",
    "                    obs, reward, done, _, _ = self.env.step(action)\n",
    "                    ep_reward += reward\n",
    "                self.rewards.append(ep_reward)\n",
    "            mean_reward = np.mean(self.rewards)\n",
    "            std_reward = np.std(self.rewards)\n",
    "            mlflow.log_metric(\"test_reward\", mean_reward, step=self.num_timesteps)\n",
    "            mlflow.log_metric(\"test_reward_std\", std_reward, step=self.num_timesteps)\n",
    "        return True"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Resnet152"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:39:33.016477Z",
     "start_time": "2025-06-15T22:25:35.158596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=ResNet152FeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    ")\n",
    "total_timesteps = 100000\n",
    "progress_bar_callback = TQDMProgressCallback(total_timesteps=total_timesteps)\n",
    "ml_callback = MLflowCallback(\n",
    "    \"models/dqn_resnet152_weights.zip\",\n",
    "    experiment_name=\"DQN_SpaceInvaders\",\n",
    "    run_name=\"DQN_Run\",\n",
    "    log_freq=500\n",
    ")\n",
    "experiment_name = \"DQN_SpaceInvaders\"\n",
    "exist_experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if not exist_experiment:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"DQN_Run_ResNet152_finetuned\"):\n",
    "    mlflow.log_param(\"env_name\", env_name)\n",
    "    mlflow.log_param(\"total_timesteps\", total_timesteps)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
    "    mlflow.log_param(\"buffer_size\", 100000)\n",
    "\n",
    "    model = DQN(\"CnnPolicy\", env, verbose=1, learning_rate=1e-4, buffer_size=100000, policy_kwargs=policy_kwargs)\n",
    "    t_model = model.learn(total_timesteps=total_timesteps, callback=[progress_bar_callback, ml_callback, TestCallBack(env)])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training Progress:   0%|          | 0/100000 [00:00<?, ?step/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c499d7db03bd43a0af113b4682d09769"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 762      |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 3046     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 736      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 907      |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 7254     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 1788     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.0518   |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 422      |\n",
      "|    total_timesteps  | 9981     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000445 |\n",
      "|    n_updates        | 2470     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 20       |\n",
      "|    time_elapsed     | 615      |\n",
      "|    total_timesteps  | 12501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00241  |\n",
      "|    n_updates        | 3100     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 775      |\n",
      "|    ep_rew_mean      | 11.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 717      |\n",
      "|    total_timesteps  | 15509    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 3852     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 775      |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 822      |\n",
      "|    total_timesteps  | 18597    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00135  |\n",
      "|    n_updates        | 4624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 1015     |\n",
      "|    total_timesteps  | 21651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 5387     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 768      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 1115     |\n",
      "|    total_timesteps  | 24581    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 6120     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 757      |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 1205     |\n",
      "|    total_timesteps  | 27235    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0414   |\n",
      "|    n_updates        | 6783     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 1291     |\n",
      "|    total_timesteps  | 29759    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 7414     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 728      |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 1457     |\n",
      "|    total_timesteps  | 32040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 7984     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 732      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 1561     |\n",
      "|    total_timesteps  | 35115    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 8753     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 1681     |\n",
      "|    total_timesteps  | 38668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 9641     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 1876     |\n",
      "|    total_timesteps  | 41059    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00603  |\n",
      "|    n_updates        | 10239    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 1975     |\n",
      "|    total_timesteps  | 43998    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 737      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2082     |\n",
      "|    total_timesteps  | 47139    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 11759    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 735      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 2280     |\n",
      "|    total_timesteps  | 50001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00315  |\n",
      "|    n_updates        | 12475    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 743      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2399     |\n",
      "|    total_timesteps  | 53529    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 13357    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 751      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2520     |\n",
      "|    total_timesteps  | 57102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 14250    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 759      |\n",
      "|    ep_rew_mean      | 11.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2743     |\n",
      "|    total_timesteps  | 60690    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 15147    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 760      |\n",
      "|    ep_rew_mean      | 11.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2849     |\n",
      "|    total_timesteps  | 63811    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 15927    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 751      |\n",
      "|    ep_rew_mean      | 11.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2927     |\n",
      "|    total_timesteps  | 66121    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 16505    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 758      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3048     |\n",
      "|    total_timesteps  | 69719    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 17404    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | 11.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3184     |\n",
      "|    total_timesteps  | 71623    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 17880    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 750      |\n",
      "|    ep_rew_mean      | 11.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3299     |\n",
      "|    total_timesteps  | 75041    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00518  |\n",
      "|    n_updates        | 18735    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 742      |\n",
      "|    ep_rew_mean      | 11.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3375     |\n",
      "|    total_timesteps  | 77292    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 19297    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 727      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3571     |\n",
      "|    total_timesteps  | 80001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00534  |\n",
      "|    n_updates        | 19975    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 728      |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3663     |\n",
      "|    total_timesteps  | 82743    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 20660    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 731      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3762     |\n",
      "|    total_timesteps  | 85646    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 21386    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3859     |\n",
      "|    total_timesteps  | 88523    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 22105    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 718      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 4011     |\n",
      "|    total_timesteps  | 90372    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00466  |\n",
      "|    n_updates        | 22567    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 712      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 4097     |\n",
      "|    total_timesteps  | 92885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00812  |\n",
      "|    n_updates        | 23196    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 712      |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 4198     |\n",
      "|    total_timesteps  | 95801    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00455  |\n",
      "|    n_updates        | 23925    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 712      |\n",
      "|    ep_rew_mean      | 11.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 4287     |\n",
      "|    total_timesteps  | 98436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 24583    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MobileNetV2"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "foSlxWH1Gb2b",
    "ExecuteTime": {
     "end_time": "2025-06-16T00:10:24.978348Z",
     "start_time": "2025-06-15T23:43:55.269243Z"
    }
   },
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MobileNetFeatureExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    ")\n",
    "total_timesteps = 100000\n",
    "progress_bar_callback = TQDMProgressCallback(total_timesteps=total_timesteps)\n",
    "ml_callback = MLflowCallback(\n",
    "    \"models/dqn_mobilenet_v2_weights.zip\",\n",
    "    experiment_name=\"DQN_SpaceInvaders\",\n",
    "    run_name=\"DQN_Run\",\n",
    "    log_freq=500\n",
    ")\n",
    "experiment_name = \"DQN_SpaceInvaders\"\n",
    "exist_experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if not exist_experiment:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"DQN_Run_MobileNetv2_finetuned\"):\n",
    "    mlflow.log_param(\"env_name\", env_name)\n",
    "    mlflow.log_param(\"total_timesteps\", total_timesteps)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
    "    mlflow.log_param(\"buffer_size\", 100000)\n",
    "\n",
    "    model = DQN(\"CnnPolicy\", env, verbose=1, learning_rate=1e-4, buffer_size=100000, policy_kwargs=policy_kwargs)\n",
    "    t_model = model.learn(total_timesteps=total_timesteps, callback=[progress_bar_callback, ml_callback, TestCallBack(env)])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /home/kaiki/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
      "\n",
      "  0%|          | 0.00/13.6M [00:00<?, ?B/s]\u001B[A\n",
      "  1%|          | 128k/13.6M [00:00<00:16, 875kB/s]\u001B[A\n",
      "  4%|▎         | 512k/13.6M [00:00<00:06, 2.15MB/s]\u001B[A\n",
      " 11%|█         | 1.50M/13.6M [00:00<00:02, 5.33MB/s]\u001B[A\n",
      " 30%|███       | 4.12M/13.6M [00:00<00:00, 13.2MB/s]\u001B[A\n",
      " 64%|██████▍   | 8.75M/13.6M [00:00<00:00, 24.9MB/s]\u001B[A\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 20.6MB/s]\u001B[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training Progress:   0%|          | 0/100000 [00:00<?, ?step/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e42396c4b7714726b22247bce9787961"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 675      |\n",
      "|    ep_rew_mean      | 8.5      |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 108      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 2700     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000309 |\n",
      "|    n_updates        | 649      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 634      |\n",
      "|    ep_rew_mean      | 8.75     |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 113      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 5076     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000805 |\n",
      "|    n_updates        | 1243     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 659      |\n",
      "|    ep_rew_mean      | 9.17     |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 111      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 7905     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 1951     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 625      |\n",
      "|    ep_rew_mean      | 8.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 73       |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 10001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 2475     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 658      |\n",
      "|    ep_rew_mean      | 9.1      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 76       |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 13164    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000803 |\n",
      "|    n_updates        | 3265     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 702      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 16853    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 4188     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 677      |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 79       |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 18946    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 4711     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 681      |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 21785    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000796 |\n",
      "|    n_updates        | 5421     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 680      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 24465    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 6091     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 700      |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 389      |\n",
      "|    total_timesteps  | 28020    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 6979     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 682      |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 447      |\n",
      "|    total_timesteps  | 30001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 7475     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 681      |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 479      |\n",
      "|    total_timesteps  | 32698    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 8149     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 684      |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 513      |\n",
      "|    total_timesteps  | 35548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000625 |\n",
      "|    n_updates        | 8861     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 683      |\n",
      "|    ep_rew_mean      | 10.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 547      |\n",
      "|    total_timesteps  | 38223    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 9530     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 701      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 621      |\n",
      "|    total_timesteps  | 42070    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00263  |\n",
      "|    n_updates        | 10492    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 706      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 660      |\n",
      "|    total_timesteps  | 45212    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 11277    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 706      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 693      |\n",
      "|    total_timesteps  | 47977    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0352   |\n",
      "|    n_updates        | 11969    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 693      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 716      |\n",
      "|    total_timesteps  | 49894    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00287  |\n",
      "|    n_updates        | 12448    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 697      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 794      |\n",
      "|    total_timesteps  | 52935    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 13208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 696      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 827      |\n",
      "|    total_timesteps  | 55657    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00253  |\n",
      "|    n_updates        | 13889    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 698      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 863      |\n",
      "|    total_timesteps  | 58629    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 14632    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 687      |\n",
      "|    ep_rew_mean      | 10.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 926      |\n",
      "|    total_timesteps  | 60428    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 15081    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 689      |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 963      |\n",
      "|    total_timesteps  | 63415    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 15828    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 690      |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 996      |\n",
      "|    total_timesteps  | 66217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 16529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 693      |\n",
      "|    ep_rew_mean      | 10.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 1033     |\n",
      "|    total_timesteps  | 69287    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000822 |\n",
      "|    n_updates        | 17296    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 704      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 1124     |\n",
      "|    total_timesteps  | 73115    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 18253    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 710      |\n",
      "|    ep_rew_mean      | 11.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 1160     |\n",
      "|    total_timesteps  | 76040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0334   |\n",
      "|    n_updates        | 18984    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 708      |\n",
      "|    ep_rew_mean      | 11.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 1193     |\n",
      "|    total_timesteps  | 78741    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 19660    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 714      |\n",
      "|    ep_rew_mean      | 11.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 1262     |\n",
      "|    total_timesteps  | 81427    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00352  |\n",
      "|    n_updates        | 20331    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 705      |\n",
      "|    ep_rew_mean      | 11.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 64       |\n",
      "|    time_elapsed     | 1293     |\n",
      "|    total_timesteps  | 83707    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 20901    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 699      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 1331     |\n",
      "|    total_timesteps  | 86711    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 21652    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 703      |\n",
      "|    ep_rew_mean      | 11       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 65       |\n",
      "|    time_elapsed     | 1364     |\n",
      "|    total_timesteps  | 89282    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 22295    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 694      |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 1445     |\n",
      "|    total_timesteps  | 91147    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00216  |\n",
      "|    n_updates        | 22761    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 693      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 1476     |\n",
      "|    total_timesteps  | 93732    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 23407    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 689      |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 1514     |\n",
      "|    total_timesteps  | 96893    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0025   |\n",
      "|    n_updates        | 24198    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ViT B-16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Cargar pesos preentrenados"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_timesteps = 100000\n",
    "progress_bar_callback = TQDMProgressCallback(total_timesteps=total_timesteps)\n",
    "ml_callback = MLflowCallback(\n",
    "    best_model_path=\"models/dqn_vit_b_16_weights.zip\",\n",
    "    experiment_name=\"DQN_SpaceInvaders\",\n",
    "    run_name=\"DQN_Run\",\n",
    "    log_freq=500\n",
    ")\n",
    "experiment_name = \"DQN_SpaceInvaders\"\n",
    "exist_experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if not exist_experiment:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"DQN_Run_Vit_b_16_finetuned\"):\n",
    "    mlflow.log_param(\"env_name\", env_name)\n",
    "    mlflow.log_param(\"total_timesteps\", total_timesteps)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
    "    mlflow.log_param(\"buffer_size\", 100000)\n",
    "    model = DQN.load(\"models/dqn_vit_b_16_weights.zip\", env=env)\n",
    "    t_model = model.learn(total_timesteps=total_timesteps, callback=[progress_bar_callback, ml_callback])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T22:25:35.138235Z",
     "start_time": "2025-06-15T20:56:56.269451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=VitB16FeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    ")\n",
    "total_timesteps = 100000\n",
    "progress_bar_callback = TQDMProgressCallback(total_timesteps=total_timesteps)\n",
    "ml_callback = MLflowCallback(\n",
    "    best_model_path=\"models/dqn_vit_b_16_weights_grey.zip\",\n",
    "    experiment_name=\"DQN_SpaceInvaders\",\n",
    "    run_name=\"DQN_Run\",\n",
    "    log_freq=500\n",
    ")\n",
    "experiment_name = \"DQN_SpaceInvaders\"\n",
    "exist_experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if not exist_experiment:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"DQN_Run_Vit_b_16_gray_finetuned\"):\n",
    "    mlflow.log_param(\"env_name\", env_name)\n",
    "    mlflow.log_param(\"total_timesteps\", total_timesteps)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
    "    mlflow.log_param(\"buffer_size\", 100000)\n",
    "\n",
    "    model = DQN(\"CnnPolicy\", env, verbose=1, learning_rate=1e-4, buffer_size=100000, policy_kwargs=policy_kwargs)\n",
    "    t_model = model.learn(total_timesteps=total_timesteps, callback=[progress_bar_callback, ml_callback, TestCallBack(env)])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training Progress:   0%|          | 0/100000 [00:00<?, ?step/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67cac3a120004b0aa1699b376f15aa5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 863      |\n",
      "|    ep_rew_mean      | 11.8     |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 3453     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 838      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 802      |\n",
      "|    ep_rew_mean      | 11.2     |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 399      |\n",
      "|    total_timesteps  | 6420     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 1579     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 725      |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 504      |\n",
      "|    total_timesteps  | 8696     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 2148     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 759      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 719      |\n",
      "|    total_timesteps  | 12145    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000366 |\n",
      "|    n_updates        | 3011     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 782      |\n",
      "|    ep_rew_mean      | 12.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 884      |\n",
      "|    total_timesteps  | 15644    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.32e-05 |\n",
      "|    n_updates        | 3885     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 820      |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 1076     |\n",
      "|    total_timesteps  | 19678    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 4894     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 802      |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 1246     |\n",
      "|    total_timesteps  | 22470    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000363 |\n",
      "|    n_updates        | 5592     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 828      |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 1442     |\n",
      "|    total_timesteps  | 26490    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000152 |\n",
      "|    n_updates        | 6597     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 824      |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 1596     |\n",
      "|    total_timesteps  | 29668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00011  |\n",
      "|    n_updates        | 7391     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 820      |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 1787     |\n",
      "|    total_timesteps  | 32811    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000213 |\n",
      "|    n_updates        | 8177     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 826      |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 1998     |\n",
      "|    total_timesteps  | 36328    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000126 |\n",
      "|    n_updates        | 9056     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 823      |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 2149     |\n",
      "|    total_timesteps  | 39498    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000182 |\n",
      "|    n_updates        | 9849     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 817      |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 2335     |\n",
      "|    total_timesteps  | 42466    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 10591    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 846      |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 2568     |\n",
      "|    total_timesteps  | 47358    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000286 |\n",
      "|    n_updates        | 11814    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 841      |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 2760     |\n",
      "|    total_timesteps  | 50485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.68e-05 |\n",
      "|    n_updates        | 12596    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 847      |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 2935     |\n",
      "|    total_timesteps  | 54219    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 13529    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 864      |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 3153     |\n",
      "|    total_timesteps  | 58738    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000131 |\n",
      "|    n_updates        | 14659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 866      |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 3373     |\n",
      "|    total_timesteps  | 62386    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 15571    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 861      |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 3517     |\n",
      "|    total_timesteps  | 65444    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00015  |\n",
      "|    n_updates        | 16335    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 858      |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 3670     |\n",
      "|    total_timesteps  | 68629    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000467 |\n",
      "|    n_updates        | 17132    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 842      |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 3811     |\n",
      "|    total_timesteps  | 70724    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000129 |\n",
      "|    n_updates        | 17655    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 837      |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 3946     |\n",
      "|    total_timesteps  | 73626    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000446 |\n",
      "|    n_updates        | 18381    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 831      |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4079     |\n",
      "|    total_timesteps  | 76444    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000572 |\n",
      "|    n_updates        | 19085    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4240     |\n",
      "|    total_timesteps  | 79892    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000102 |\n",
      "|    n_updates        | 19947    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 815      |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4360     |\n",
      "|    total_timesteps  | 81506    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000143 |\n",
      "|    n_updates        | 20351    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 809      |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4494     |\n",
      "|    total_timesteps  | 84362    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00019  |\n",
      "|    n_updates        | 21065    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 830      |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4729     |\n",
      "|    total_timesteps  | 89381    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000355 |\n",
      "|    n_updates        | 22320    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 834      |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4907     |\n",
      "|    total_timesteps  | 92077    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.66e-05 |\n",
      "|    n_updates        | 22994    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 836      |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 5077     |\n",
      "|    total_timesteps  | 95707    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 23901    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNNConnectedDeep"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T00:56:58.381482Z",
     "start_time": "2025-06-16T00:18:56.735083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CNNConnectedDeep,\n",
    "    features_extractor_kwargs=dict(features_dim=256)\n",
    ")\n",
    "total_timesteps = 100000\n",
    "progress_bar_callback = TQDMProgressCallback(total_timesteps=total_timesteps)\n",
    "ml_callback = MLflowCallback(\n",
    "    best_model_path=\"models/dqn_cnn_connected_deep_weights.zip\",\n",
    "    experiment_name=\"DQN_SpaceInvaders\",\n",
    "    run_name=\"DQN_Run\",\n",
    "    log_freq=500\n",
    ")\n",
    "experiment_name = \"DQN_SpaceInvaders\"\n",
    "exist_experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if not exist_experiment:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run(run_name=\"DQN_Run_CNNConnectedDeep_finetuned\"):\n",
    "    mlflow.log_param(\"env_name\", env_name)\n",
    "    mlflow.log_param(\"total_timesteps\", total_timesteps)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
    "    mlflow.log_param(\"buffer_size\", 100000)\n",
    "\n",
    "    model = DQN(\"CnnPolicy\", env, verbose=1, learning_rate=1e-4, buffer_size=100000, policy_kwargs=policy_kwargs)\n",
    "    t_model = model.learn(total_timesteps=total_timesteps, callback=[progress_bar_callback, ml_callback, TestCallBack(env)])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training Progress:   0%|          | 0/100000 [00:00<?, ?step/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d199edc7b0754736bb2bb8ede78b8849"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 772      |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 3090     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000369 |\n",
      "|    n_updates        | 747      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 760      |\n",
      "|    ep_rew_mean      | 11.6     |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 47       |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 6082     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000173 |\n",
      "|    n_updates        | 1495     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 833      |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 10001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 2475     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 853      |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 13641    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 3385     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 799      |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 15986    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 3971     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 770      |\n",
      "|    ep_rew_mean      | 11.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 45       |\n",
      "|    time_elapsed     | 408      |\n",
      "|    total_timesteps  | 18471    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000258 |\n",
      "|    n_updates        | 4592     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 738      |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 470      |\n",
      "|    total_timesteps  | 20667    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 5141     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | 11.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 556      |\n",
      "|    total_timesteps  | 24740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000907 |\n",
      "|    n_updates        | 6159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 792      |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 636      |\n",
      "|    total_timesteps  | 28499    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000899 |\n",
      "|    n_updates        | 7099     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 764      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 698      |\n",
      "|    total_timesteps  | 30575    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 7618     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 770      |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 768      |\n",
      "|    total_timesteps  | 33879    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00087  |\n",
      "|    n_updates        | 8444     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 758      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 821      |\n",
      "|    total_timesteps  | 36382    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00412  |\n",
      "|    n_updates        | 9070     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 895      |\n",
      "|    total_timesteps  | 39860    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 9939     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 754      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 956      |\n",
      "|    total_timesteps  | 42236    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.04     |\n",
      "|    n_updates        | 10533    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 749      |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1014     |\n",
      "|    total_timesteps  | 44945    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 11211    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 757      |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1087     |\n",
      "|    total_timesteps  | 48429    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0317   |\n",
      "|    n_updates        | 12082    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 760      |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1171     |\n",
      "|    total_timesteps  | 51690    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00239  |\n",
      "|    n_updates        | 12897    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 757      |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1231     |\n",
      "|    total_timesteps  | 54512    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0346   |\n",
      "|    n_updates        | 13602    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 754      |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1289     |\n",
      "|    total_timesteps  | 57286    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 14296    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1341     |\n",
      "|    total_timesteps  | 59693    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 14898    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 749      |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1428     |\n",
      "|    total_timesteps  | 62907    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 15701    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 762      |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1517     |\n",
      "|    total_timesteps  | 67067    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 16741    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 761      |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1596     |\n",
      "|    total_timesteps  | 70001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 17475    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 764      |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1667     |\n",
      "|    total_timesteps  | 73309    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 18302    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 759      |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1723     |\n",
      "|    total_timesteps  | 75949    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00228  |\n",
      "|    n_updates        | 18962    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 769      |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1824     |\n",
      "|    total_timesteps  | 80001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000756 |\n",
      "|    n_updates        | 19975    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 1906     |\n",
      "|    total_timesteps  | 83859    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00079  |\n",
      "|    n_updates        | 20939    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 1982     |\n",
      "|    total_timesteps  | 87424    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 21830    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 764      |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 43       |\n",
      "|    time_elapsed     | 2049     |\n",
      "|    total_timesteps  | 90001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 22475    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 771      |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 2116     |\n",
      "|    total_timesteps  | 93128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00312  |\n",
      "|    n_updates        | 23256    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 2172     |\n",
      "|    total_timesteps  | 95750    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 23912    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 784      |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 44       |\n",
      "|    time_elapsed     | 2244     |\n",
      "|    total_timesteps  | 99079    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 24744    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHYryKd1Gb2b"
   },
   "outputs": [],
   "source": [
    "# Testing part to calculate the mean reward\n",
    "weights_filename = 'dqn_{}_weights.h5f'.format(env_name)\n",
    "dqn.load_weights(weights_filename)\n",
    "dqn.test(env, nb_episodes=10, visualize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NAlu8b1Gb2b"
   },
   "source": [
    "3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "ANFQiicXK3sO"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
